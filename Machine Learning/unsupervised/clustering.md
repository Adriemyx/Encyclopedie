<h1 align='center'> Machine learning - Clustering üë•</h1>


Dans ce document sera pr√©sent√© quelques bases de code, notamment avec la libraire `scikit-learn`, pour faire du clustering sur python.


## K-Means
K-means est un algorithme de clustering non supervis√© utilis√© pour partitionner un ensemble de donn√©es en **K** groupes (ou clusters) bas√©s sur des caract√©ristiques similaires. 

```python
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split

# S√©paration 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Choix du nombre de classes pour s√©parer les donn√©es
nb_clusters = ...

# Cr√©ation d'un objet KMeans avec nb_clusters clusters
kmeans = KMeans(n_clusters=nb_clusters)  

# Ajustement du mod√®le sur les donn√©es d'entra√Ænement
kmeans.fit(X_train)  

# Pr√©diction des clusters pour chaque point de X_train
y_pred = kmeans.predict(X_train)

```

*<u>Remarque:</u> Ici $\mathcal{X}$ peut √™tre une matrice ou un vecteur*.



<br>
<br>

## PCA
La PCA, ou **Analyse en Composantes Principales** (Principal Component Analysis en anglais), est une technique de r√©duction de dimensionnalit√© en identifiant les directions dans lesquelles les donn√©es varient le plus (appel√©es composantes principales). 


```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# Choix de la taille de la r√©duction 
nb_dim = ...

# Cr√©ation de l'objet PCA et r√©duction √† nb_dim 
pca = PCA(n_components=nb_dim)

# Ajustement et transformation des donn√©es
X_reduced = pca.fit_transform(X)  

# Affichage des r√©sultats
plt.figure(figsize=(22, 8))
scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, edgecolor='k')
plt.xlabel('Composante Principale 1')
plt.ylabel('Composante Principale 2')
plt.colorbar(scatter, ticks=[0, 1, 2], label='Classe')
plt.grid()
plt.show()
```
<br>

Dans le cas o√π il n'y a pas d'objectifs de dimension:
```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(df)

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

df_pca = pd.DataFrame(X_pca, columns=['X1', 'X2'])

print(f"Variance expliqu√©e par la premi√®re composante : {pca.explained_variance_ratio_[0]:.2f}")
print(f"Variance expliqu√©e par la deuxi√®me composante : {pca.explained_variance_ratio_[1]:.2f}")

plt.figure(figsize=(22, 8))
plt.scatter(df_pca['X1'], df_pca['X2'])
plt.xlabel('Composante principale 1')
plt.ylabel('Composante principale 2')
plt.title('Projection des param√®tres sur les deux premi√®res composantes principales')
plt.show()
```